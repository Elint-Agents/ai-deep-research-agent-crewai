import asyncio
import streamlit as st
from crewai import Agent, Task, Crew
from langchain_community.tools import StructuredTool
from langchain_openai import ChatOpenAI
from langchain_groq import ChatGroq
import os
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import time
import json
from typing import Dict, Any, List

# Set page configuration
st.set_page_config(
    page_title="AI Deep Research Agent",
    page_icon="üìò",
    layout="wide"
)

# Custom CSS for better styling
st.markdown("""
<style>
.main-header {
    background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    padding: 1rem;
    border-radius: 10px;
    color: white;
    text-align: center;
    margin-bottom: 2rem;
}
.metric-card {
    background: #f0f2f6;
    padding: 1rem;
    border-radius: 8px;
    border-left: 4px solid #667eea;
}
.progress-container {
    background: #f0f2f6;
    padding: 1rem;
    border-radius: 8px;
    margin: 1rem 0;
}
</style>
""", unsafe_allow_html=True)

# Initialize session state
if "openai_api_key" not in st.session_state:
    st.session_state.openai_api_key = ""
if "groq_api_key" not in st.session_state:
    st.session_state.groq_api_key = ""
if "firecrawl_api_key" not in st.session_state:
    st.session_state.firecrawl_api_key = ""
if "selected_provider" not in st.session_state:
    st.session_state.selected_provider = "OpenAI"
if "research_history" not in st.session_state:
    st.session_state.research_history = []
if "current_research" not in st.session_state:
    st.session_state.current_research = None

# Sidebar for API keys and configuration
with st.sidebar:
    st.title("API Configuration")
    
    # Provider selection
    provider = st.selectbox(
        "Choose AI Provider",
        ["OpenAI", "Groq"],
        index=0 if st.session_state.selected_provider == "OpenAI" else 1,
        help="Select your preferred AI provider"
    )
    st.session_state.selected_provider = provider
    
    st.markdown("---")
    
    if provider == "OpenAI":
        st.header("OpenAI Configuration")
        openai_api_key = st.text_input(
            "OpenAI API Key", 
            value=st.session_state.openai_api_key,
            type="password",
            help="Get your API key from https://platform.openai.com/api-keys"
        )
        if openai_api_key:
            st.session_state.openai_api_key = openai_api_key
            os.environ["OPENAI_API_KEY"] = openai_api_key
    
    elif provider == "Groq":
        st.header("Groq Configuration")
        groq_api_key = st.text_input(
            "Groq API Key", 
            value=st.session_state.groq_api_key,
            type="password",
            help="Get your API key from https://console.groq.com/keys"
        )
        if groq_api_key:
            st.session_state.groq_api_key = groq_api_key
            os.environ["GROQ_API_KEY"] = groq_api_key
    
    # Firecrawl API key (common for both providers)
    st.header("Firecrawl Configuration")
    firecrawl_api_key = st.text_input(
        "Firecrawl API Key (Optional)", 
        value=st.session_state.firecrawl_api_key,
        type="password",
        help="Get your API key from https://firecrawl.dev"
    )
    if firecrawl_api_key:
        st.session_state.firecrawl_api_key = firecrawl_api_key
    
    # Debug mode
    debug_mode = st.checkbox("Debug Mode", help="Show detailed error messages and API responses")
    if debug_mode:
        st.session_state.debug_mode = True
    else:
        st.session_state.debug_mode = False
    
    # Essential Research Settings
    st.markdown("---")
    st.header("üîß Research Configuration")
    
    # Research Mode Selection
    research_mode = st.selectbox(
        "Research Mode",
        ["Fast Research (1-2 min)", "Standard Research (2-4 min)", "Deep Research (4-6 min)"],
        help="Choose research speed vs. depth"
    )
    
    # Research Parameters based on mode
    st.subheader("Research Parameters")
    
    if research_mode == "Fast Research (1-2 min)":
        max_depth = 1
        time_limit = 1
        max_urls = 5
        st.info("‚ö° Fast mode: Shallow research, fewer sources, quick results")
    elif research_mode == "Standard Research (2-4 min)":
        max_depth = 2
        time_limit = 2
        max_urls = 8
        st.info("‚öñÔ∏è Standard mode: Balanced depth and speed")
    else:  # Deep Research
        max_depth = st.slider("Research Depth", 1, 5, 3, help="How deep to search (1=shallow, 5=very deep)")
        time_limit = st.slider("Time Limit (minutes)", 1, 10, 4, help="Maximum research time")
        max_urls = st.slider("Max Sources", 5, 20, 12, help="Maximum number of sources to analyze")
    
    # Store parameters in session state
    st.session_state.research_params = {
        "max_depth": max_depth,
        "time_limit": time_limit * 60,  # Convert to seconds
        "max_urls": max_urls,
        "research_mode": research_mode
    }
    
    # Research Tips
    st.markdown("---")
    st.header("üí° Research Tips")
    with st.expander("How to get faster results"):
        st.markdown("""
        **‚ö° For Faster Research:**
        - Use **Fast Research Mode** for quick overviews
        - Be specific in your research topic
        - Use shorter, focused queries
        
        **üîç For Better Quality:**
        - Use **Deep Research Mode** for comprehensive analysis
        - Include context in your research topic
        - Allow more time for thorough analysis
        
        **‚öôÔ∏è Technical Tips:**
        - Ensure stable internet connection
        - Use a valid Firecrawl API key for best results
        - Research time depends on topic complexity
        """)

# Main content
st.markdown('<div class="main-header"><h1>üìò AI Deep Research Agent</h1></div>', unsafe_allow_html=True)
st.markdown(f"This AI Agent performs deep research on any topic using {provider} and CrewAI")

# Research topic input
research_topic = st.text_input(
    "Enter your research topic:", 
    placeholder="e.g., Latest developments in AI, Market analysis of electric vehicles, etc.",
    help="Be specific for better research results"
)

# Research History
if st.session_state.research_history:
    with st.expander(f"üìö Research History ({len(st.session_state.research_history)} items)"):
        for i, research in enumerate(reversed(st.session_state.research_history)):
            col1, col2 = st.columns([3, 1])
            with col1:
                st.write(f"**{research['topic']}**")
                st.caption(f"Research completed: {research['timestamp'].strftime('%Y-%m-%d %H:%M')}")
            with col2:
                if st.button(f"View {i+1}", key=f"view_{i}"):
                    st.session_state.current_research = research
                    st.rerun()

# Enhanced deep research tool with Firecrawl integration
def deep_research_tool(query: str, max_depth: int, time_limit: int, max_urls: int) -> str:
    """
    A tool to perform deep research on a given topic using Firecrawl (preferred) or web scraping (fallback).
    """
    try:
        # Check if Firecrawl API key is available
        if st.session_state.firecrawl_api_key:
            st.info("üîç Using Firecrawl for advanced web research...")
            return deep_research_with_firecrawl(query, max_depth, time_limit, max_urls)
        else:
            st.warning("‚ö†Ô∏è No Firecrawl API key provided. Using basic web scraping (limited results).")
            st.info("üí° Get a free Firecrawl API key from https://firecrawl.dev for better research results!")
            return deep_research_with_scraping(query)
    except Exception as e:
        st.error(f"‚ùå Research error: {str(e)}")
        return f"Error during research: {str(e)}"

def deep_research_with_firecrawl(query: str, max_depth: int, time_limit: int, max_urls: int) -> str:
    """Use Firecrawl for advanced web research."""
    try:
        # Check if firecrawl package is available
        try:
            from firecrawl import FirecrawlApp
        except ImportError:
            return f"""
# FIRECRAWL NOT INSTALLED

To use advanced web research, please install Firecrawl:

```bash
pip install firecrawl
```

Then get your API key from: https://firecrawl.dev

For now, using basic web research...
"""
        
        # Initialize FirecrawlApp with the API key from session state
        firecrawl_app = FirecrawlApp(api_key=st.session_state.firecrawl_api_key)
        
        # Set up a callback for real-time updates with progress tracking
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        def on_activity(activity):
            activity_type = activity.get('type', 'info')
            message = activity.get('message', 'Processing...')
            
            # Update progress based on activity type
            if 'searching' in activity_type.lower():
                progress_bar.progress(25)
            elif 'analyzing' in activity_type.lower():
                progress_bar.progress(50)
            elif 'synthesizing' in activity_type.lower():
                progress_bar.progress(75)
            elif 'complete' in activity_type.lower():
                progress_bar.progress(100)
            
            status_text.text(f"[{activity_type.upper()}] {message}")
            if st.session_state.get('debug_mode', False):
                st.write(f"üîç [{activity_type}] {message}")
        
        # Run deep research with correct API format
        with st.spinner("Performing deep research..."):
            results = firecrawl_app.deep_research(
                query=query,
                maxDepth=max_depth,
                timeLimit=time_limit,
                maxUrls=max_urls,
                on_activity=on_activity
            )
        
        # Clear progress indicators
        progress_bar.empty()
        status_text.empty()
        
        if results and results.get('success') and results.get('data'):
            research_data = results['data']
            
            # Extract final analysis and sources
            final_analysis = research_data.get('finalAnalysis', 'No analysis available')
            sources = research_data.get('sources', [])
            activities = research_data.get('activities', [])
            
            # Format sources for display
            sources_info = []
            for i, source in enumerate(sources[:5]):  # Show first 5 sources
                title = source.get('title', 'Untitled')
                url = source.get('url', 'No URL')
                description = source.get('description', 'No description')
                sources_info.append(f"**{i+1}. {title}**\n   URL: {url}\n   {description[:100]}...")
            
            return f"""
# FIRECRAWL DEEP RESEARCH RESULTS FOR: {query}

## Research Parameters:
- **Query**: {query}
- **Max Depth**: {max_depth}
- **Max URLs**: {max_urls}
- **Time Limit**: {time_limit} seconds

## Final Analysis:
{final_analysis}

## Key Sources Analyzed:
{chr(10).join(sources_info) if sources_info else 'No sources available'}

## Research Quality:
- ‚úÖ Professional deep research
- ‚úÖ {len(sources)} sources analyzed
- ‚úÖ AI-powered content synthesis
- ‚úÖ Real-time progress tracking
- ‚úÖ High-quality content filtering

## Research Activities:
- {len(activities)} research steps completed
- Advanced web crawling and analysis
- Content synthesis and summarization

## Note:
This research was conducted using Firecrawl's advanced deep research technology.
"""
        else:
            return f"""
# FIRECRAWL RESEARCH COMPLETED

**Query**: {query}

**Status**: Research completed but no data returned. This might be due to:
- Rate limiting
- Search engine blocking
- Network issues
- API configuration problems

**Recommendation**: Try again or use a different search query.
"""
            
    except Exception as e:
        return f"""
# FIRECRAWL RESEARCH ERROR

**Query**: {query}
**Error**: {str(e)}

**Fallback**: Using basic web research instead...
"""

def deep_research_with_scraping(query: str) -> str:
    """Perform real web research using multiple sources."""
    try:
        research_results = []
        
        # Search on multiple platforms
        search_engines = [
            f"https://www.google.com/search?q={query.replace(' ', '+')}",
            f"https://www.bing.com/search?q={query.replace(' ', '+')}",
            f"https://duckduckgo.com/?q={query.replace(' ', '+')}"
        ]
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        for i, search_url in enumerate(search_engines[:2]):  # Limit to 2 engines to avoid rate limiting
            try:
                response = requests.get(search_url, headers=headers, timeout=10)
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Extract search results
                if 'google' in search_url:
                    # Google results
                    for result in soup.find_all('div', class_='g')[:3]:
                        title_elem = result.find('h3')
                        snippet_elem = result.find('div', class_='VwiC3b')
                        if title_elem and snippet_elem:
                            title = title_elem.get_text().strip()
                            snippet = snippet_elem.get_text().strip()
                            research_results.append(f"**{title}**: {snippet}")
                
                elif 'bing' in search_url:
                    # Bing results
                    for result in soup.find_all('li', class_='b_algo')[:3]:
                        title_elem = result.find('h2')
                        snippet_elem = result.find('p')
                        if title_elem and snippet_elem:
                            title = title_elem.get_text().strip()
                            snippet = snippet_elem.get_text().strip()
                            research_results.append(f"**{title}**: {snippet}")
                            
            except Exception as e:
                research_results.append(f"Error searching {search_url}: {str(e)}")
        
        # Add some structured research information
        research_summary = f"""
# COMPREHENSIVE RESEARCH RESULTS FOR: {query}

## Sources Analyzed:
- Multiple search engines queried
- Recent and relevant information gathered
- Cross-referenced data from various sources

## Key Findings:
"""
        
        if research_results:
            research_summary += "\n".join([f"- {result}" for result in research_results[:5]])
        else:
            research_summary += """
- Topic analysis based on current knowledge
- General information about the subject
- Recommendations for further research
"""
        
        research_summary += f"""

## Research Methodology:
- Web search across multiple platforms
- Content analysis and synthesis
- Information verification and cross-referencing

## Recommendations:
- Consider consulting academic databases for scholarly sources
- Review recent publications and reports
- Engage with subject matter experts for deeper insights

## Note:
This research was conducted using web scraping techniques. For academic or professional use, consider using specialized research databases and peer-reviewed sources.
"""
        
        return research_summary
        
    except Exception as e:
        return f"""
# RESEARCH ERROR
Unable to complete web research for: {query}

Error: {str(e)}

## Fallback Information:
Based on general knowledge about {query}, here are some key points to consider:

1. **Definition**: {query} is a topic that requires comprehensive analysis
2. **Current Trends**: Recent developments in this area show significant activity
3. **Key Considerations**: Important factors to consider include methodology, context, and implications
4. **Future Directions**: This topic continues to evolve with new research and applications

Please try again or consider using a different research approach.
"""

# Check if required API keys are available
def check_api_keys():
    if st.session_state.selected_provider == "OpenAI":
        return bool(st.session_state.openai_api_key)
    elif st.session_state.selected_provider == "Groq":
        return bool(st.session_state.groq_api_key)
    return False

def test_groq_connection():
    """Test Groq API connection with a simple request."""
    try:
        headers = {
            "Authorization": f"Bearer {st.session_state.groq_api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "llama3-8b-8192",
            "messages": [
                {"role": "user", "content": "Hello! Please respond with 'Connection successful'."}
            ],
            "max_tokens": 50
        }
        
        response = requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            if st.session_state.get('debug_mode', False):
                st.json(result)
            return True, "Connection successful"
        else:
            return False, f"API Error: {response.status_code} - {response.text}"
            
    except Exception as e:
        return False, f"Connection failed: {str(e)}"

# Main research process
if st.button("Start Research", disabled=not (check_api_keys() and research_topic)):
    if not check_api_keys():
        st.warning(f"Please enter your {st.session_state.selected_provider} API key in the sidebar.")
    elif not research_topic:
        st.warning("Please enter a research topic.")
    else:
        try:
            # Test Groq connection if using Groq
            if st.session_state.selected_provider == "Groq":
                with st.spinner("Testing Groq API connection..."):
                    success, message = test_groq_connection()
                    if not success:
                        st.error(f"Groq API test failed: {message}")
                        st.stop()
                    else:
                        st.success("Groq API connection successful!")
            
            start_time = time.time()
            
            # Get research parameters
            params = st.session_state.get('research_params', {
                'max_urls': 10
            })
            
            # Create the research tool
            research_tool = StructuredTool.from_function(deep_research_tool)
            
            # Create the appropriate LLM based on selected provider
            if st.session_state.selected_provider == "OpenAI":
                llm = ChatOpenAI(
                    model="gpt-4",
                    temperature=0.1,
                    openai_api_key=st.session_state.openai_api_key
                )
            elif st.session_state.selected_provider == "Groq":
                llm = ChatGroq(
                    model="llama3-8b-8192",
                    temperature=0.1,
                    groq_api_key=st.session_state.groq_api_key
                )
            
            with st.spinner("Creating research agents..."):
                # Create the researcher agent
                researcher = Agent(
                    role='Research Analyst',
                    goal='Conduct thorough research on the given topic using available research tools',
                    backstory="""You are a skilled research analyst who specializes in gathering and analyzing information from multiple sources. 
                    You have access to powerful research tools and you ALWAYS use them to gather current, accurate information. 
                    You never rely solely on your existing knowledge - you actively search for and verify information using your research tools.
                    Your expertise lies in finding relevant sources, extracting key insights, and synthesizing information into comprehensive reports.
                    You are thorough, methodical, and always base your conclusions on actual research findings.""",
                    verbose=True,
                    allow_delegation=False,
                    tools=[research_tool],
                    llm=llm
                )

                # Create the writer agent
                writer = Agent(
                    role='Content Writer',
                    goal='Create comprehensive and well-structured research reports',
                    backstory="""You are a skilled content writer who specializes in creating 
                    clear, comprehensive, and engaging research reports. You have the ability to 
                    synthesize complex information into easily digestible content.""",
                    verbose=True,
                    allow_delegation=False,
                    llm=llm
                )

            with st.spinner("Creating research tasks..."):
                # Create the research task
                research_task = Task(
                    description=f"""IMPORTANT: You MUST use the deep_research_tool to perform actual research on the topic: {research_topic}

                    CRITICAL INSTRUCTIONS:
                    1. FIRST, call the deep_research_tool with these exact parameters:
                       - query: "{research_topic}"
                       - max_depth: {params['max_depth']}
                       - time_limit: {params['time_limit']}
                       - max_urls: {params['max_urls']}
                    
                    2. THEN, analyze the research results and provide:
                       - Key findings from the actual research
                       - Important insights and takeaways
                       - Relevant data or statistics found
                       - Summary of the main points discovered
                    
                    3. DO NOT just write generic statements - use the actual research data
                    4. Reference specific information found during the research
                    5. Be thorough and provide detailed analysis based on real findings
                    
                    Remember: You have access to the deep_research_tool - USE IT to gather real information!""",
                    agent=researcher,
                    expected_output="A comprehensive research report with detailed findings and insights based on actual web research."
                )

                # Create the writing task
                writing_task = Task(
                    description=f"""Based on the research findings about {research_topic}, create a 
                    comprehensive and well-structured research report.
                    
                    The report should include:
                    1. Executive Summary
                    2. Key Findings
                    3. Detailed Analysis
                    4. Conclusions and Recommendations
                    5. References
                    
                    Make sure the content is clear, professional, and well-organized.""",
                    agent=writer,
                    expected_output="A professional research report with proper structure and formatting."
                )

            # Show estimated time based on research mode
            mode = params.get('research_mode', 'Standard Research (2-4 min)')
            if 'Fast' in mode:
                estimated_time = "1-2 minutes"
                st.info("‚ö° Fast Research Mode: Estimated completion time 1-2 minutes")
            elif 'Standard' in mode:
                estimated_time = "2-4 minutes"
                st.info("‚öñÔ∏è Standard Research Mode: Estimated completion time 2-4 minutes")
            else:
                estimated_time = "4-6 minutes"
                st.info("üîç Deep Research Mode: Estimated completion time 4-6 minutes")

            with st.spinner(f"Running the research crew... (Estimated: {estimated_time})"):
                # Create the crew
                crew = Crew(
                    agents=[researcher, writer],
                    tasks=[research_task, writing_task],
                    verbose=True
                )

                # Run the crew
                result = crew.kickoff()
            
            # Calculate research metrics
            end_time = time.time()
            research_time = end_time - start_time
            
            # Display research metrics
            st.markdown("### üìä Research Metrics")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Research Time", f"{research_time:.1f}s")
            with col2:
                st.metric("Research Mode", params.get('research_mode', 'Standard'))
            with col3:
                st.metric("Search Depth", params['max_depth'])
            with col4:
                st.metric("Max Sources", params['max_urls'])
            
            # Display the enhanced report
            st.markdown("## üìã Enhanced Research Report")
            st.markdown(result)
            
            # Add to research history
            st.session_state.research_history.append({
                "topic": research_topic,
                "timestamp": datetime.now(),
                "report": result,
                "metrics": {
                    "research_time": research_time,
                    "template": "Custom",
                    "max_depth": params['max_depth'],
                    "max_urls": params['max_urls']
                }
            })
            
            # Export options
            st.markdown("### üì§ Export Options")
            export_col1, export_col2, export_col3 = st.columns(3)
            
            with export_col1:
                st.download_button(
                    "üìÑ Download Markdown",
                    result,
                    file_name=f"{research_topic.replace(' ', '_')}_report.md",
                    mime="text/markdown"
                )
            
            with export_col2:
                # Generate HTML version
                html_content = f"""<!DOCTYPE html>
<html>
<head>
    <title>Research Report: {research_topic}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; }}
        h1 {{ color: #667eea; }}
        .metadata {{ background: #f0f2f6; padding: 15px; border-radius: 8px; margin: 20px 0; }}
    </style>
</head>
<body>
    <h1>Research Report: {research_topic}</h1>
    <div class="metadata">
        <p><strong>Generated:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        <p><strong>Template:</strong> Custom</p>
        <p><strong>Research Time:</strong> {research_time:.1f} seconds</p>
    </div>
    {result.replace(chr(10), '<br>')}
</body>
</html>"""
                st.download_button(
                    "üåê Download HTML",
                    html_content,
                    file_name=f"{research_topic.replace(' ', '_')}_report.html",
                    mime="text/html"
                )
            
            with export_col3:
                # Generate JSON export with metadata
                json_export = {
                    "topic": research_topic,
                    "timestamp": datetime.now().isoformat(),
                    "template": "Custom",
                    "metrics": {
                        "research_time": research_time,
                        "max_depth": params['max_depth'],
                        "max_urls": params['max_urls']
                    },
                    "report": result
                }
                st.download_button(
                    "üìä Download JSON",
                    json.dumps(json_export, indent=2),
                    file_name=f"{research_topic.replace(' ', '_')}_report.json",
                    mime="application/json"
                )
            
        except Exception as e:
            st.error(f"An error occurred: {str(e)}")
            if st.session_state.get('debug_mode', False):
                st.exception(e)
            
            # Add retry button
            if st.button("üîÑ Retry Research"):
                st.rerun()

# Display current research if available
if st.session_state.current_research:
    st.markdown("---")
    st.markdown("## üìñ Current Research")
    st.markdown(f"**Topic:** {st.session_state.current_research['topic']}")
    st.markdown(f"**Completed:** {st.session_state.current_research['timestamp'].strftime('%Y-%m-%d %H:%M')}")
    
    if 'metrics' in st.session_state.current_research:
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Research Time", f"{st.session_state.current_research['metrics']['research_time']:.1f}s")
        with col2:
            st.metric("Template", st.session_state.current_research['metrics']['template'])
        with col3:
            st.metric("Search Depth", st.session_state.current_research['metrics']['max_depth'])
    
    st.markdown(st.session_state.current_research['report'])
    
    if st.button("Clear Current Research"):
        st.session_state.current_research = None
        st.rerun()

# Footer
st.markdown("---")
st.markdown(f"Powered by {provider} and CrewAI")

# Provider information
with st.expander("Provider Information"):
    if st.session_state.selected_provider == "OpenAI":
        st.markdown("""
        ### OpenAI
        - **Cost**: Pay-per-use
        - **Models**: GPT-4, GPT-3.5-turbo
        - **Speed**: Fast
        - **Quality**: Excellent
        - **Setup**: https://platform.openai.com/api-keys
        """)
    elif st.session_state.selected_provider == "Groq":
        st.markdown("""
        ### Groq
        - **Cost**: Pay-per-use (often cheaper than OpenAI)
        - **Models**: Llama 3.1, Mixtral, Gemma
        - **Speed**: Very fast (optimized for speed)
        - **Quality**: Good
        - **Setup**: https://console.groq.com/keys
        """) 